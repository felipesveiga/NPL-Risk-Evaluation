{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5514a9f7",
   "metadata": {
    "papermill": {
     "duration": 0.015284,
     "end_time": "2023-12-12T10:11:59.509626",
     "exception": false,
     "start_time": "2023-12-12T10:11:59.494342",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 style='font-size:40px'> NPL Risk Evaluation Modeling</h1>\n",
    "<div style='font-size:20px'> \n",
    "    <ul> \n",
    "        <li> \n",
    "            This project aims the conceiving of a Machine Learning Model focused on assisting a bank on its credit approval strategy.\n",
    "        </li>\n",
    "        <li> \n",
    "            The corporation has been scolded for its recent NPL levels by its shareholders. Thus, the executive team has decided that a more conservative \n",
    "            credit strategy must be adopted for new contracts.\n",
    "        </li>\n",
    "        <li> \n",
    "            During the planning meetings, the business team has made two major requests concerning the nature of the model.\n",
    "            <ul style='list-style-type:decimal'> \n",
    "                <li> \n",
    "                    It must be focused on predicting whether a given client might produce an NPL in the future.\n",
    "                </li>\n",
    "                <li> \n",
    "                    The output must be some kind of score suggesting the likelihood of the event to happen. They are not looking for \n",
    "                    an incisive \"yes or no\" answer.\n",
    "                </li>\n",
    "            </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    "    <p style='margin-left:30px'> <strong> Note:</strong> The bank's NPL definition is any loan which payment is at least 90 days late.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03925bf",
   "metadata": {
    "papermill": {
     "duration": 0.014241,
     "end_time": "2023-12-12T10:11:59.540656",
     "exception": false,
     "start_time": "2023-12-12T10:11:59.526415",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h2 style='font-size:30px'> Data Importing</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            The Data Engineers were able to provide two .csv views from the bank's database. The first one contains general information over the clients \n",
    "            and the second lists the loans they've contracted over some period of time.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbd98245",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T10:11:59.572403Z",
     "iopub.status.busy": "2023-12-12T10:11:59.571660Z",
     "iopub.status.idle": "2023-12-12T10:12:56.886680Z",
     "shell.execute_reply": "2023-12-12T10:12:56.884760Z"
    },
    "papermill": {
     "duration": 57.335038,
     "end_time": "2023-12-12T10:12:56.890448",
     "exception": false,
     "start_time": "2023-12-12T10:11:59.555410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\r\n",
      "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: py4j==0.10.9.7 in /opt/conda/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\r\n",
      "Building wheels for collected packages: pyspark\r\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425350 sha256=6f292a396e2d53816ead9910bb2b9679ab185bfc743b23da15b00af9bf58d31f\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\r\n",
      "Successfully built pyspark\r\n",
      "Installing collected packages: pyspark\r\n",
      "Successfully installed pyspark-3.5.0\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f69bcf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T10:12:56.951698Z",
     "iopub.status.busy": "2023-12-12T10:12:56.951096Z",
     "iopub.status.idle": "2023-12-12T10:13:03.884379Z",
     "shell.execute_reply": "2023-12-12T10:13:03.883041Z"
    },
    "papermill": {
     "duration": 6.967349,
     "end_time": "2023-12-12T10:13:03.887262",
     "exception": false,
     "start_time": "2023-12-12T10:12:56.919913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/12/12 10:13:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "# Creating the project's SparkSession.\n",
    "spark = SparkSession.builder.appName('NPL').getOrCreate()\n",
    "\n",
    "# Also, modifying the session's log level.\n",
    "log_level = spark.sparkContext.setLogLevel('ERROR')\n",
    "\n",
    "# This tiny config enables us to scroll along the DataFrame's columns.\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f696b734",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-15T16:05:33.192895Z",
     "iopub.status.busy": "2023-08-15T16:05:33.192467Z",
     "iopub.status.idle": "2023-08-15T16:05:34.343874Z",
     "shell.execute_reply": "2023-08-15T16:05:34.342739Z",
     "shell.execute_reply.started": "2023-08-15T16:05:33.192858Z"
    },
    "papermill": {
     "duration": 0.028466,
     "end_time": "2023-12-12T10:13:03.943165",
     "exception": false,
     "start_time": "2023-12-12T10:13:03.914699",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Clients Database</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            This dataset is comprised of general information about the loans' clients.\n",
    "        </li>    \n",
    "        <li> \n",
    "            A particularity worth noting is that date columns show the negative amount of days since the given event took place. Positive numbers \n",
    "            indicate the number of days since the occurence ceased to exist - as it might happen with unemployed borrowers in the DAYS_EMPLOYED feature.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06dc47a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T10:13:03.999757Z",
     "iopub.status.busy": "2023-12-12T10:13:03.999056Z",
     "iopub.status.idle": "2023-12-12T10:13:12.181848Z",
     "shell.execute_reply": "2023-12-12T10:13:12.180592Z"
    },
    "papermill": {
     "duration": 8.216299,
     "end_time": "2023-12-12T10:13:12.185815",
     "exception": false,
     "start_time": "2023-12-12T10:13:03.969516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+------------+---------------+------------+----------------+--------------------+--------------------+--------------------+-----------------+----------+-------------+----------+---------------+----------+----------+---------------+---------------+\n",
      "|     ID|CODE_GENDER|FLAG_OWN_CAR|FLAG_OWN_REALTY|CNT_CHILDREN|AMT_INCOME_TOTAL|    NAME_INCOME_TYPE| NAME_EDUCATION_TYPE|  NAME_FAMILY_STATUS|NAME_HOUSING_TYPE|DAYS_BIRTH|DAYS_EMPLOYED|FLAG_MOBIL|FLAG_WORK_PHONE|FLAG_PHONE|FLAG_EMAIL|OCCUPATION_TYPE|CNT_FAM_MEMBERS|\n",
      "+-------+-----------+------------+---------------+------------+----------------+--------------------+--------------------+--------------------+-----------------+----------+-------------+----------+---------------+----------+----------+---------------+---------------+\n",
      "|5008804|          M|           Y|              Y|           0|        427500.0|             Working|    Higher education|      Civil marriage| Rented apartment|    -12005|        -4542|         1|              1|         0|         0|           NULL|            2.0|\n",
      "|5008805|          M|           Y|              Y|           0|        427500.0|             Working|    Higher education|      Civil marriage| Rented apartment|    -12005|        -4542|         1|              1|         0|         0|           NULL|            2.0|\n",
      "|5008806|          M|           Y|              Y|           0|        112500.0|             Working|Secondary / secon...|             Married|House / apartment|    -21474|        -1134|         1|              0|         0|         0| Security staff|            2.0|\n",
      "|5008808|          F|           N|              Y|           0|        270000.0|Commercial associate|Secondary / secon...|Single / not married|House / apartment|    -19110|        -3051|         1|              0|         1|         1|    Sales staff|            1.0|\n",
      "|5008809|          F|           N|              Y|           0|        270000.0|Commercial associate|Secondary / secon...|Single / not married|House / apartment|    -19110|        -3051|         1|              0|         1|         1|    Sales staff|            1.0|\n",
      "+-------+-----------+------------+---------------+------------+----------------+--------------------+--------------------+--------------------+-----------------+----------+-------------+----------+---------------+----------+----------+---------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_clients = '/kaggle/input/credit-card-approval-prediction/application_record.csv'\n",
    "\n",
    "# Defining the data types from the clients dataset.\n",
    "schema_clients = '''\n",
    "`ID` STRING, `CODE_GENDER` STRING, `FLAG_OWN_CAR` STRING, `FLAG_OWN_REALTY` STRING, `CNT_CHILDREN` INT,\n",
    "`AMT_INCOME_TOTAL` FLOAT, `NAME_INCOME_TYPE` STRING, `NAME_EDUCATION_TYPE` STRING, `NAME_FAMILY_STATUS` STRING, `NAME_HOUSING_TYPE` STRING,\n",
    "`DAYS_BIRTH` INT, `DAYS_EMPLOYED` INT, `FLAG_MOBIL` STRING, `FLAG_WORK_PHONE` STRING, `FLAG_PHONE` STRING, `FLAG_EMAIL` STRING, \n",
    "`OCCUPATION_TYPE` STRING, `CNT_FAM_MEMBERS` DOUBLE\n",
    "'''\n",
    "\n",
    "# Reading the database with the created schema.\n",
    "df_clients = spark.read.csv(path_clients, header=True, schema=schema_clients)\n",
    "df_clients.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f5079d",
   "metadata": {
    "papermill": {
     "duration": 0.02787,
     "end_time": "2023-12-12T10:13:12.251194",
     "exception": false,
     "start_time": "2023-12-12T10:13:12.223324",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> Duplicates Disclaimer</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "             Clients may not have unique rows in the dataset because the ID column identifies a contracted loan instead of a person.\n",
    "        </li>\n",
    "        <li> \n",
    "            Thus, I've found convenient for the project to create an ID column that assigns a code for each of the clients.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fa268b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T10:13:12.309315Z",
     "iopub.status.busy": "2023-12-12T10:13:12.308780Z",
     "iopub.status.idle": "2023-12-12T10:13:16.958128Z",
     "shell.execute_reply": "2023-12-12T10:13:16.956814Z"
    },
    "papermill": {
     "duration": 4.683663,
     "end_time": "2023-12-12T10:13:16.961970",
     "exception": false,
     "start_time": "2023-12-12T10:13:12.278307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|     ID|count|\n",
      "+-------+-----+\n",
      "|7742298|    2|\n",
      "|7174719|    2|\n",
      "|7091721|    2|\n",
      "|7089090|    2|\n",
      "|7022197|    2|\n",
      "+-------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Another issue unnoticed by the Data Engineers is that the database contains repeated Loan ID's.\n",
    "from pyspark.sql.functions import max as ps_max\n",
    "\n",
    "# Observe that there are Loans mentioned two times. It would be proper to disconsider them. \n",
    "data_duplicate_id = (df_clients\n",
    "                     .groupBy('ID')\n",
    "                     .count()\n",
    "                     .filter('`count`>1')\n",
    "                            )\n",
    "data_duplicate_id.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "932d2907",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T10:13:17.022479Z",
     "iopub.status.busy": "2023-12-12T10:13:17.022077Z",
     "iopub.status.idle": "2023-12-12T10:13:19.738420Z",
     "shell.execute_reply": "2023-12-12T10:13:19.736587Z"
    },
    "papermill": {
     "duration": 2.751965,
     "end_time": "2023-12-12T10:13:19.742447",
     "exception": false,
     "start_time": "2023-12-12T10:13:16.990482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:=======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+------------+---------------+------------+----------------+----------------+--------------------+------------------+-----------------+----------+-------------+----------+---------------+----------+----------+---------------+---------------+\n",
      "|     ID|CODE_GENDER|FLAG_OWN_CAR|FLAG_OWN_REALTY|CNT_CHILDREN|AMT_INCOME_TOTAL|NAME_INCOME_TYPE| NAME_EDUCATION_TYPE|NAME_FAMILY_STATUS|NAME_HOUSING_TYPE|DAYS_BIRTH|DAYS_EMPLOYED|FLAG_MOBIL|FLAG_WORK_PHONE|FLAG_PHONE|FLAG_EMAIL|OCCUPATION_TYPE|CNT_FAM_MEMBERS|\n",
      "+-------+-----------+------------+---------------+------------+----------------+----------------+--------------------+------------------+-----------------+----------+-------------+----------+---------------+----------+----------+---------------+---------------+\n",
      "|7742298|          F|           N|              Y|           0|        144000.0|         Working|Secondary / secon...|             Widow|House / apartment|    -20626|        -1455|         1|              0|         0|         0|  Cooking staff|            1.0|\n",
      "|7742298|          M|           N|              N|           0|        112500.0|         Working|Secondary / secon...|           Married|House / apartment|    -18239|        -5428|         1|              1|         0|         0|           NULL|            2.0|\n",
      "+-------+-----------+------------+---------------+------------+----------------+----------------+--------------------+------------------+-----------------+----------+-------------+----------+---------------+----------+----------+---------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# If we take a peek on the first mentioned ID, we can notice that the presented loan actually is assigned to two different people!\n",
    "\n",
    "# Thus, the presence of such deals is potentially harmful for our model. It would be sensible to discard such ID's from the database.\n",
    "df_clients.filter('`ID`==7742298').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0afef2c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T10:13:19.808266Z",
     "iopub.status.busy": "2023-12-12T10:13:19.807223Z",
     "iopub.status.idle": "2023-12-12T10:13:19.924795Z",
     "shell.execute_reply": "2023-12-12T10:13:19.923597Z"
    },
    "papermill": {
     "duration": 0.153101,
     "end_time": "2023-12-12T10:13:19.929041",
     "exception": false,
     "start_time": "2023-12-12T10:13:19.775940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dropping out the problematic loans.\n",
    "df_clients = data_duplicate_id.join(df_clients, how='right', on='ID').where('`count` IS NULL').drop('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37eeeb93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T10:13:20.016847Z",
     "iopub.status.busy": "2023-12-12T10:13:20.016204Z",
     "iopub.status.idle": "2023-12-12T10:13:20.064013Z",
     "shell.execute_reply": "2023-12-12T10:13:20.062839Z"
    },
    "papermill": {
     "duration": 0.095574,
     "end_time": "2023-12-12T10:13:20.067617",
     "exception": false,
     "start_time": "2023-12-12T10:13:19.972043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CODE_GENDER',\n",
       " 'FLAG_OWN_CAR',\n",
       " 'FLAG_OWN_REALTY',\n",
       " 'CNT_CHILDREN',\n",
       " 'AMT_INCOME_TOTAL',\n",
       " 'NAME_INCOME_TYPE',\n",
       " 'NAME_EDUCATION_TYPE',\n",
       " 'NAME_FAMILY_STATUS',\n",
       " 'NAME_HOUSING_TYPE',\n",
       " 'DAYS_BIRTH',\n",
       " 'DAYS_EMPLOYED',\n",
       " 'FLAG_MOBIL',\n",
       " 'FLAG_WORK_PHONE',\n",
       " 'FLAG_PHONE',\n",
       " 'FLAG_EMAIL',\n",
       " 'OCCUPATION_TYPE',\n",
       " 'CNT_FAM_MEMBERS']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Listing the `df_clients` features with the exception of ID.\n",
    "features_clients = df_clients.columns\n",
    "features_clients.remove('ID')\n",
    "features_clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ad8c4ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T10:13:20.212998Z",
     "iopub.status.busy": "2023-12-12T10:13:20.212450Z",
     "iopub.status.idle": "2023-12-12T10:13:30.663166Z",
     "shell.execute_reply": "2023-12-12T10:13:30.661763Z"
    },
    "papermill": {
     "duration": 10.484857,
     "end_time": "2023-12-12T10:13:30.667987",
     "exception": false,
     "start_time": "2023-12-12T10:13:20.183130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`df_clients` length: 438463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:===========================================>              (3 + 1) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clients: 90084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Now, getting back to the Client's ID issue, I'd like to present a brief analysis on it.\n",
    "# Note that the database's actual amount of clients is lower than its number of rows. \n",
    "data_clients = df_clients.dropDuplicates(features_clients) \n",
    "print(f'`df_clients` length: {df_clients.count()}')\n",
    "print(f'Number of clients: {data_clients.count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8e8ebc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T10:13:30.739412Z",
     "iopub.status.busy": "2023-12-12T10:13:30.738864Z",
     "iopub.status.idle": "2023-12-12T10:13:30.904757Z",
     "shell.execute_reply": "2023-12-12T10:13:30.903539Z"
    },
    "papermill": {
     "duration": 0.204509,
     "end_time": "2023-12-12T10:13:30.910636",
     "exception": false,
     "start_time": "2023-12-12T10:13:30.706127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We'll assign an ID for every client mentioned in `df_clients`. \n",
    "from pyspark.sql.functions import cast, row_number\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "window = Window.orderBy(features_clients)\n",
    "row_window = row_number().over(window)\n",
    "\n",
    "# A DataFrame with the clients' data and actual ID.\n",
    "df_id_clients = data_clients.withColumn('ID_CLIENT', row_window.cast(StringType())).drop('ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c232f683",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T10:13:30.979096Z",
     "iopub.status.busy": "2023-12-12T10:13:30.978726Z",
     "iopub.status.idle": "2023-12-12T10:13:43.968362Z",
     "shell.execute_reply": "2023-12-12T10:13:43.966910Z"
    },
    "papermill": {
     "duration": 13.032368,
     "end_time": "2023-12-12T10:13:43.972842",
     "exception": false,
     "start_time": "2023-12-12T10:13:30.940474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 35:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+------------+---------------+------------+----------------+----------------+--------------------+------------------+-----------------+----------+-------------+----------+---------------+----------+----------+---------------+---------------+---------+\n",
      "|     ID|CODE_GENDER|FLAG_OWN_CAR|FLAG_OWN_REALTY|CNT_CHILDREN|AMT_INCOME_TOTAL|NAME_INCOME_TYPE| NAME_EDUCATION_TYPE|NAME_FAMILY_STATUS|NAME_HOUSING_TYPE|DAYS_BIRTH|DAYS_EMPLOYED|FLAG_MOBIL|FLAG_WORK_PHONE|FLAG_PHONE|FLAG_EMAIL|OCCUPATION_TYPE|CNT_FAM_MEMBERS|ID_CLIENT|\n",
      "+-------+-----------+------------+---------------+------------+----------------+----------------+--------------------+------------------+-----------------+----------+-------------+----------+---------------+----------+----------+---------------+---------------+---------+\n",
      "|5996382|          F|           N|              N|           0|         28800.0|       Pensioner|Secondary / secon...|           Married|House / apartment|    -20298|       365243|         1|              0|         1|         0|           NULL|            2.0|        7|\n",
      "|5996383|          F|           N|              N|           0|         28800.0|       Pensioner|Secondary / secon...|           Married|House / apartment|    -20298|       365243|         1|              0|         1|         0|           NULL|            2.0|        7|\n",
      "|5996384|          F|           N|              N|           0|         28800.0|       Pensioner|Secondary / secon...|           Married|House / apartment|    -20298|       365243|         1|              0|         1|         0|           NULL|            2.0|        7|\n",
      "|6499066|          F|           N|              N|           0|         29133.0|       Pensioner|Secondary / secon...|           Married|House / apartment|    -20945|       365243|         1|              0|         1|         0|           NULL|            2.0|        8|\n",
      "|6499067|          F|           N|              N|           0|         29133.0|       Pensioner|Secondary / secon...|           Married|House / apartment|    -20945|       365243|         1|              0|         1|         0|           NULL|            2.0|        8|\n",
      "+-------+-----------+------------+---------------+------------+----------------+----------------+--------------------+------------------+-----------------+----------+-------------+----------+---------------+----------+----------+---------------+---------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# We'll need to perform Null Safe JOIN's, since columns such as 'OCCUPATION_TYPE' contain null values.\n",
    "from functools import reduce\n",
    "\n",
    "# Creating the multiple null safe JOIN's condition.\n",
    "condition_id_client = reduce(lambda x,y: x&y, [df_clients[col].eqNullSafe(df_id_clients[col]) for col in features_clients])\n",
    "columns_join_id = ['df_clients.*', 'df_id_clients.ID_CLIENT'] # Listing the JOIN columns.\n",
    "\n",
    "# Consolidating the final clients database.\n",
    "df_clients = (df_clients.alias('df_clients') # Resorting to aliases for both DataFrames present columns with same names.\n",
    "                 .join(df_id_clients.alias('df_id_clients'), condition_id_client)\n",
    "                 .select(columns_join_id))\n",
    "df_clients.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ba8ae9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-15T16:05:33.192895Z",
     "iopub.status.busy": "2023-08-15T16:05:33.192467Z",
     "iopub.status.idle": "2023-08-15T16:05:34.343874Z",
     "shell.execute_reply": "2023-08-15T16:05:34.342739Z",
     "shell.execute_reply.started": "2023-08-15T16:05:33.192858Z"
    },
    "papermill": {
     "duration": 0.038084,
     "end_time": "2023-12-12T10:13:44.056331",
     "exception": false,
     "start_time": "2023-12-12T10:13:44.018247",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Loans Database</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            This table contains the payments records for every loan since its contraction. \n",
    "        </li>\n",
    "        <li> \n",
    "            But in order to the dataset be adequate to our project's intent, two transformations are necessary: first, we need to bring the `ID_CLIENT`\n",
    "            column to it and after that, group the database so that it denounces individuals who've produced an NPL at least once.            \n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20b01df0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T10:13:44.120283Z",
     "iopub.status.busy": "2023-12-12T10:13:44.119745Z",
     "iopub.status.idle": "2023-12-12T10:13:44.318605Z",
     "shell.execute_reply": "2023-12-12T10:13:44.317372Z"
    },
    "papermill": {
     "duration": 0.235747,
     "end_time": "2023-12-12T10:13:44.322941",
     "exception": false,
     "start_time": "2023-12-12T10:13:44.087194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+------+\n",
      "|     ID|MONTHS_BALANCE|STATUS|\n",
      "+-------+--------------+------+\n",
      "|5001711|             0|     X|\n",
      "|5001711|            -1|     0|\n",
      "|5001711|            -2|     0|\n",
      "|5001711|            -3|     0|\n",
      "|5001712|             0|     C|\n",
      "+-------+--------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bringing the dataset into our notebook.\n",
    "path_loans = '/kaggle/input/credit-card-approval-prediction/credit_record.csv'\n",
    "schema_loans = '`ID` STRING, `MONTHS_BALANCE` INT, `STATUS` STRING'\n",
    "df_loans = spark.read.csv(path_loans, header=True, schema=schema_loans)\n",
    "df_loans.show(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01138db0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T10:13:44.413792Z",
     "iopub.status.busy": "2023-12-12T10:13:44.412801Z",
     "iopub.status.idle": "2023-12-12T10:13:59.554733Z",
     "shell.execute_reply": "2023-12-12T10:13:59.550606Z"
    },
    "papermill": {
     "duration": 15.190701,
     "end_time": "2023-12-12T10:13:59.559292",
     "exception": false,
     "start_time": "2023-12-12T10:13:44.368591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 52:=============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+--------------+------+\n",
      "|ID_CLIENT|     ID|MONTHS_BALANCE|STATUS|\n",
      "+---------+-------+--------------+------+\n",
      "|    34269|5008810|             0|     C|\n",
      "|    34269|5008810|            -1|     C|\n",
      "|    34269|5008810|            -2|     C|\n",
      "|    34269|5008810|            -3|     C|\n",
      "|    34269|5008810|            -4|     C|\n",
      "+---------+-------+--------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Now, providing the loans' client ID.\n",
    "df_loans = df_loans.join(df_clients, ['ID']).select(['ID_CLIENT', 'ID', 'MONTHS_BALANCE', 'STATUS'])\n",
    "df_loans.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160c18b4",
   "metadata": {
    "papermill": {
     "duration": 0.044106,
     "end_time": "2023-12-12T10:13:59.648590",
     "exception": false,
     "start_time": "2023-12-12T10:13:59.604484",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> Conceiving the Target Variable</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            The `STATUS` column presents a handful of codes that represent distinct status for a loan's payment. Their definition is as follows:\n",
    "            <table style='font-size:15px;margin-top:20px'> \n",
    "                <tr>\n",
    "                    <th> Code</th>\n",
    "                    <th> Definition</th>\n",
    "                </tr>\n",
    "                <tr> \n",
    "                    <td> C</td>\n",
    "                    <td> Paid off that month</td>\n",
    "                </tr>\n",
    "                <tr> \n",
    "                    <td> 0</td>\n",
    "                    <td> 1-29 days past due</td>\n",
    "                </tr>\n",
    "                <tr> \n",
    "                    <td> 1</td>\n",
    "                    <td> 30-59 days past due </td>\n",
    "                </tr>\n",
    "                <tr> \n",
    "                    <td> 2</td>\n",
    "                    <td> 60-89 days past due </td>\n",
    "                </tr>\n",
    "                <tr> \n",
    "                    <td> 3</td>\n",
    "                    <td> 90-119 days past due </td>\n",
    "                </tr>\n",
    "                <tr> \n",
    "                    <td> 4</td>\n",
    "                    <td> 120-149 days past due </td>\n",
    "                </tr>\n",
    "                <tr> \n",
    "                    <td> 5</td>\n",
    "                    <td> Overdue or bad debts,<p> write-offs for more than 150 days</p> </td>\n",
    "                </tr>\n",
    "                <tr> \n",
    "                    <td> X</td>\n",
    "                    <td> No loan for the month</td>\n",
    "                </tr>\n",
    "            </table>\n",
    "        </li>\n",
    "        <li style='margin-top:20px'> \n",
    "            Observe that in our case only the 3, 4 and 5 codes are of our interest. Thus it would be convenient to create a binary flag that denounces whether \n",
    "            the individual has ever caused an NPL.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08bec7d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T10:13:59.739145Z",
     "iopub.status.busy": "2023-12-12T10:13:59.738612Z",
     "iopub.status.idle": "2023-12-12T10:14:01.094862Z",
     "shell.execute_reply": "2023-12-12T10:14:01.086130Z"
    },
    "papermill": {
     "duration": 1.406107,
     "end_time": "2023-12-12T10:14:01.099176",
     "exception": false,
     "start_time": "2023-12-12T10:13:59.693069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The dependent variable's conception needs a custom GroupBy that PySpark is unable to perform by itself. Hence, we \n",
    "# are going to resort to pandas in this section.\n",
    "import pandas as pd\n",
    "\n",
    "# Defining the GroupBy's schema.\n",
    "schema_flag_npl = '`ID_CLIENT` STRING, `NPL` STRING'\n",
    "\n",
    "# This lambda expression signs whether a client has ever produced an NPL in the past.\n",
    "lambda_npl = lambda x: '1' if x.STATUS.isin(['3', '4', '5']).any() else '0'\n",
    "\n",
    "def has_npl(df:pd.DataFrame)->pd.DataFrame:\n",
    "    '''\n",
    "        Verifies if a client's  records contain any sort of Non-Performing Loan.\n",
    "        \n",
    "        Parameter\n",
    "        ---------\n",
    "        `df`: pd.DataFrame \n",
    "            The loan records of a certain client.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        A `pd.DataFrame` with the client's ID and a flag indicating NPL existence in their loan history. \n",
    "    '''\n",
    "    output = df.groupby(['ID_CLIENT']).apply(lambda_npl) # `lambda_npl` takes care of the flags creation.\n",
    "    output.name = 'NPL' # Setting the flag column's name.\n",
    "    return output.reset_index()\n",
    "\n",
    "# Finally, generating our target-variable.\n",
    "target = df_loans.groupBy('ID_CLIENT').applyInPandas(has_npl, schema_flag_npl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c020577",
   "metadata": {
    "papermill": {
     "duration": 0.03778,
     "end_time": "2023-12-12T10:14:01.191642",
     "exception": false,
     "start_time": "2023-12-12T10:14:01.153862",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h2 style='font-size:30px'> Consolidating the Data</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            With both datasets properly treated, we are able to JOIN them in a single table.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f014d8de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T10:14:01.258772Z",
     "iopub.status.busy": "2023-12-12T10:14:01.258220Z",
     "iopub.status.idle": "2023-12-12T10:14:01.326929Z",
     "shell.execute_reply": "2023-12-12T10:14:01.325421Z"
    },
    "papermill": {
     "duration": 0.107375,
     "end_time": "2023-12-12T10:14:01.330825",
     "exception": false,
     "start_time": "2023-12-12T10:14:01.223450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Finally, enriching the clients information with the NPL flag.\n",
    "df = df_id_clients.join(target, how='inner', on='ID_CLIENT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c439c531",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T10:14:01.425042Z",
     "iopub.status.busy": "2023-12-12T10:14:01.424508Z",
     "iopub.status.idle": "2023-12-12T10:14:01.430608Z",
     "shell.execute_reply": "2023-12-12T10:14:01.429471Z"
    },
    "papermill": {
     "duration": 0.057642,
     "end_time": "2023-12-12T10:14:01.433429",
     "exception": false,
     "start_time": "2023-12-12T10:14:01.375787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df.write.parquet('/kaggle/input/df-parquet', mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacce114",
   "metadata": {
    "papermill": {
     "duration": 0.044948,
     "end_time": "2023-12-12T10:14:01.523812",
     "exception": false,
     "start_time": "2023-12-12T10:14:01.478864",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h2 style='font-size:30px'> Dataset Splitting</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            With the dataset properly treated, we are able to begin our EDA and model creation. But firstly we have to separate the data in \n",
    "            the training and test tables.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41392853",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T10:14:01.621334Z",
     "iopub.status.busy": "2023-12-12T10:14:01.620326Z",
     "iopub.status.idle": "2023-12-12T10:15:14.024046Z",
     "shell.execute_reply": "2023-12-12T10:15:14.022594Z"
    },
    "papermill": {
     "duration": 72.45692,
     "end_time": "2023-12-12T10:15:14.027653",
     "exception": false,
     "start_time": "2023-12-12T10:14:01.570733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 132:============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-------------------+\n",
      "|NPL|count|         proportion|\n",
      "+---+-----+-------------------+\n",
      "|  0| 9509| 0.9774876644736842|\n",
      "|  1|  219|0.02251233552631579|\n",
      "+---+-----+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# As we can see, we are dealing with an unbalanced dataset case. Thus it is interesting to maintain the target value proportions\n",
    "# in both training and test sets.\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "df.groupBy('NPL').count().withColumn('proportion', col('count')/df.count()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01055dca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T10:15:14.138257Z",
     "iopub.status.busy": "2023-12-12T10:15:14.137719Z",
     "iopub.status.idle": "2023-12-12T10:15:14.661370Z",
     "shell.execute_reply": "2023-12-12T10:15:14.659970Z"
    },
    "papermill": {
     "duration": 0.581167,
     "end_time": "2023-12-12T10:15:14.665564",
     "exception": false,
     "start_time": "2023-12-12T10:15:14.084397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating the training and test sets.\n",
    "train = df.sampleBy('NPL', fractions={'0':.75, '1':.75}, seed=42)\n",
    "test = df.subtract(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71e1ab58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T10:15:14.761718Z",
     "iopub.status.busy": "2023-12-12T10:15:14.761229Z",
     "iopub.status.idle": "2023-12-12T10:17:17.718783Z",
     "shell.execute_reply": "2023-12-12T10:17:17.717441Z"
    },
    "papermill": {
     "duration": 123.004148,
     "end_time": "2023-12-12T10:17:17.722770",
     "exception": false,
     "start_time": "2023-12-12T10:15:14.718622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** TRAIN ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+--------------------+\n",
      "|NPL|count|          proportion|\n",
      "+---+-----+--------------------+\n",
      "|  0| 7205|  0.9785413554257776|\n",
      "|  1|  158|0.021458644574222464|\n",
      "+---+-----+--------------------+\n",
      "\n",
      "*** TEST ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+--------------------+\n",
      "|NPL|count|          proportion|\n",
      "+---+-----+--------------------+\n",
      "|  0| 2308|  0.9800424628450106|\n",
      "|  1|   47|0.019957537154989383|\n",
      "+---+-----+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Since the class proportions are relatively proximate, we are able to use them in our project.\n",
    "print('*** TRAIN ***')\n",
    "train.groupBy('NPL').count().withColumn('proportion', col('count')/train.count()).show()\n",
    "print('*** TEST ***')\n",
    "test.groupBy('NPL').count().withColumn('proportion', col('count')/test.count()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "879405e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T10:17:17.838238Z",
     "iopub.status.busy": "2023-12-12T10:17:17.837853Z",
     "iopub.status.idle": "2023-12-12T10:18:24.930773Z",
     "shell.execute_reply": "2023-12-12T10:18:24.929450Z"
    },
    "papermill": {
     "duration": 67.145093,
     "end_time": "2023-12-12T10:18:24.934612",
     "exception": false,
     "start_time": "2023-12-12T10:17:17.789519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Saving the datasets in distinct .parquet files.\n",
    "train.write.parquet('/kaggle/working/train.parquet', mode='overwrite')\n",
    "test.write.parquet('/kaggle/working/test.parquet', mode='overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3148ce51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-15T16:05:33.192895Z",
     "iopub.status.busy": "2023-08-15T16:05:33.192467Z",
     "iopub.status.idle": "2023-08-15T16:05:34.343874Z",
     "shell.execute_reply": "2023-08-15T16:05:34.342739Z",
     "shell.execute_reply.started": "2023-08-15T16:05:33.192858Z"
    },
    "papermill": {
     "duration": 0.067632,
     "end_time": "2023-12-12T10:18:25.067909",
     "exception": false,
     "start_time": "2023-12-12T10:18:25.000277",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Defining the Models' Metric</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Providing False Negatives would clearly be more harmful for the bank's equity than False Positives.         \n",
    "        </li>\n",
    "        <li> \n",
    "            Following conversations with the credit analysts, we've ended up defining the case's official metric\n",
    "            as an f-score with $\\beta=4$. So, we are giving to Recall an importance 4x higher than the Precision's.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b705603a",
   "metadata": {
    "papermill": {
     "duration": 0.071243,
     "end_time": "2023-12-12T10:18:25.205583",
     "exception": false,
     "start_time": "2023-12-12T10:18:25.134340",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h2 style='font-size:30px'> Exploratory Data Analysis</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            With the data properly segregated, let's briefly analyze its content and see whether we can spot differences \n",
    "            among the classes. \n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "147504a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T10:18:25.331314Z",
     "iopub.status.busy": "2023-12-12T10:18:25.330930Z",
     "iopub.status.idle": "2023-12-12T10:18:40.169420Z",
     "shell.execute_reply": "2023-12-12T10:18:40.167972Z"
    },
    "papermill": {
     "duration": 14.89836,
     "end_time": "2023-12-12T10:18:40.172245",
     "exception": false,
     "start_time": "2023-12-12T10:18:25.273885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /opt/conda/lib/python3.10/site-packages (3.5.0)\r\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /opt/conda/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ed948ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T10:18:40.272268Z",
     "iopub.status.busy": "2023-12-12T10:18:40.271327Z",
     "iopub.status.idle": "2023-12-12T10:18:40.287158Z",
     "shell.execute_reply": "2023-12-12T10:18:40.285430Z"
    },
    "papermill": {
     "duration": 0.070474,
     "end_time": "2023-12-12T10:18:40.290124",
     "exception": false,
     "start_time": "2023-12-12T10:18:40.219650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "# Creating the project's SparkSession.\n",
    "spark = SparkSession.builder.appName('NPL').getOrCreate()\n",
    "\n",
    "# Also, modifying the session's log level.\n",
    "log_level = spark.sparkContext.setLogLevel('ERROR')\n",
    "\n",
    "# This tiny config enables us to scroll along the DataFrame's columns.\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3304f6e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T10:18:40.390717Z",
     "iopub.status.busy": "2023-12-12T10:18:40.390279Z",
     "iopub.status.idle": "2023-12-12T10:18:40.887458Z",
     "shell.execute_reply": "2023-12-12T10:18:40.884914Z"
    },
    "papermill": {
     "duration": 0.551371,
     "end_time": "2023-12-12T10:18:40.890431",
     "exception": false,
     "start_time": "2023-12-12T10:18:40.339060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+------------+---------------+------------+----------------+----------------+--------------------+------------------+-----------------+----------+-------------+----------+---------------+----------+----------+---------------+---------------+---+\n",
      "|ID_CLIENT|CODE_GENDER|FLAG_OWN_CAR|FLAG_OWN_REALTY|CNT_CHILDREN|AMT_INCOME_TOTAL|NAME_INCOME_TYPE| NAME_EDUCATION_TYPE|NAME_FAMILY_STATUS|NAME_HOUSING_TYPE|DAYS_BIRTH|DAYS_EMPLOYED|FLAG_MOBIL|FLAG_WORK_PHONE|FLAG_PHONE|FLAG_EMAIL|OCCUPATION_TYPE|CNT_FAM_MEMBERS|NPL|\n",
      "+---------+-----------+------------+---------------+------------+----------------+----------------+--------------------+------------------+-----------------+----------+-------------+----------+---------------+----------+----------+---------------+---------------+---+\n",
      "|      691|          F|           N|              N|           0|         67500.0|         Working|Secondary / secon...|           Married|House / apartment|    -20075|        -7013|         1|              1|         1|         0|    Sales staff|            2.0|  0|\n",
      "|     3606|          F|           N|              N|           0|        112500.0|         Working|Secondary / secon...|           Married|House / apartment|     -9865|         -196|         1|              1|         0|         0|       Laborers|            2.0|  0|\n",
      "|     4821|          F|           N|              N|           0|        135000.0|   State servant|    Higher education|           Married|House / apartment|    -12490|        -1191|         1|              1|         1|         0|     Core staff|            2.0|  0|\n",
      "|     5925|          F|           N|              N|           0|        157500.0|       Pensioner|Secondary / secon...|           Married|House / apartment|    -22828|       365243|         1|              0|         0|         0|           NULL|            2.0|  0|\n",
      "|     6194|          F|           N|              N|           0|        157500.0|         Working|   Incomplete higher|           Married|House / apartment|    -16888|        -2687|         1|              0|         0|         0|     Core staff|            2.0|  0|\n",
      "+---------+-----------+------------+---------------+------------+----------------+----------------+--------------------+------------------+-----------------+----------+-------------+----------+---------------+----------+----------+---------------+---------------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = spark.read.parquet('/kaggle/input/npl-train/train.parquet/')\n",
    "train.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3980cb19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-15T16:05:33.192895Z",
     "iopub.status.busy": "2023-08-15T16:05:33.192467Z",
     "iopub.status.idle": "2023-08-15T16:05:34.343874Z",
     "shell.execute_reply": "2023-08-15T16:05:34.342739Z",
     "shell.execute_reply.started": "2023-08-15T16:05:33.192858Z"
    },
    "papermill": {
     "duration": 0.052763,
     "end_time": "2023-12-12T10:18:40.993473",
     "exception": false,
     "start_time": "2023-12-12T10:18:40.940710",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Assessing the Classes' Incomes</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            Let's analyze whether there is any revenue difference between individuals who produced an NPL and those who didn't. \n",
    "        </li>\n",
    "        <li> \n",
    "            Since we are dealing with an continuous outcome from two independent samples, I'll use the z-score formula below to examine the \n",
    "            income differences:\n",
    "            <center style='margin-top:20px'> \n",
    "                    $z=\\frac{\\overline{X}_{1}-\\overline{X}_{2}}{S_{p}\\sqrt{\\frac{1}{n_{1}}+\\frac{1}{n_{2}}}}$ | $S_{p}=\\sqrt{\\frac{(n_{1}-1)s_{1}^{2}+(n_{2}-1)s_{2}^{2}}{n_{1}+n_{2}-2}}$\n",
    "           </center>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c0be7c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T10:18:41.105846Z",
     "iopub.status.busy": "2023-12-12T10:18:41.105409Z",
     "iopub.status.idle": "2023-12-12T10:18:41.454570Z",
     "shell.execute_reply": "2023-12-12T10:18:41.453272Z"
    },
    "papermill": {
     "duration": 0.418186,
     "end_time": "2023-12-12T10:18:41.459056",
     "exception": false,
     "start_time": "2023-12-12T10:18:41.040870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------------+\n",
      "|NPL|stddev(AMT_INCOME_TOTAL)|\n",
      "+---+------------------------+\n",
      "|  0|        99647.7510722535|\n",
      "|  1|       96639.80531139452|\n",
      "+---+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The formula above is only valid for samples with similar std's (0.5<s1/s2<2). So we ought to firstly guarantee that the incomes' std's\n",
    "# are in accordance to that rule.\n",
    "df_income_std = train.groupBy('NPL').agg({'AMT_INCOME_TOTAL':'std'})\n",
    "df_income_std.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e9c1335",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T10:18:41.575654Z",
     "iopub.status.busy": "2023-12-12T10:18:41.575198Z",
     "iopub.status.idle": "2023-12-12T10:18:41.886612Z",
     "shell.execute_reply": "2023-12-12T10:18:41.885477Z"
    },
    "papermill": {
     "duration": 0.365967,
     "end_time": "2023-12-12T10:18:41.890710",
     "exception": false,
     "start_time": "2023-12-12T10:18:41.524743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0311253292695148"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Because the std ratio is in the desired interval, we can proceed in using the formula.\n",
    "list_std = [row['stddev(AMT_INCOME_TOTAL)'] for row in df_income_std.collect()]\n",
    "list_std[0] / list_std[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ad30075",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T10:18:42.041752Z",
     "iopub.status.busy": "2023-12-12T10:18:42.041067Z",
     "iopub.status.idle": "2023-12-12T10:18:44.033738Z",
     "shell.execute_reply": "2023-12-12T10:18:44.032563Z"
    },
    "papermill": {
     "duration": 2.070932,
     "end_time": "2023-12-12T10:18:44.036952",
     "exception": false,
     "start_time": "2023-12-12T10:18:41.966020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7972574858186637"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# By setting our alpha=.05, we can see that there is no statistical evidence that people with no NPL receive higher incomes\n",
    "# than the other group.\n",
    "from statsmodels.stats.weightstats import ztest\n",
    "\n",
    "zeros = [row['AMT_INCOME_TOTAL'] for row in train.select('AMT_INCOME_TOTAL').where('NPL==0').collect()]\n",
    "ones = [row['AMT_INCOME_TOTAL'] for row in train.select('AMT_INCOME_TOTAL').where('NPL==1').collect()]\n",
    "\n",
    "ztest(zeros, ones, alternative='larger')[1] # Computing our p-value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a9e47d",
   "metadata": {
    "papermill": {
     "duration": 0.072946,
     "end_time": "2023-12-12T10:18:44.182252",
     "exception": false,
     "start_time": "2023-12-12T10:18:44.109306",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Valuable Assets Analysis</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            The dataset contains columns representing whether the client possesses real state or a vehicle.\n",
    "        </li>\n",
    "        <li> \n",
    "            We can verify if people that own such properties have lower chance of producing an NPL, because they could sell them if they don't have enough \n",
    "            cash to pay the loans. \n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ecfa721d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T10:18:44.294088Z",
     "iopub.status.busy": "2023-12-12T10:18:44.293640Z",
     "iopub.status.idle": "2023-12-12T10:18:44.400298Z",
     "shell.execute_reply": "2023-12-12T10:18:44.398980Z"
    },
    "papermill": {
     "duration": 0.161678,
     "end_time": "2023-12-12T10:18:44.404329",
     "exception": false,
     "start_time": "2023-12-12T10:18:44.242651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+------------+---------------+------------+----------------+--------------------+--------------------+--------------------+-----------------+----------+-------------+----------+---------------+----------+----------+--------------------+---------------+---+\n",
      "|ID_CLIENT|CODE_GENDER|FLAG_OWN_CAR|FLAG_OWN_REALTY|CNT_CHILDREN|AMT_INCOME_TOTAL|    NAME_INCOME_TYPE| NAME_EDUCATION_TYPE|  NAME_FAMILY_STATUS|NAME_HOUSING_TYPE|DAYS_BIRTH|DAYS_EMPLOYED|FLAG_MOBIL|FLAG_WORK_PHONE|FLAG_PHONE|FLAG_EMAIL|     OCCUPATION_TYPE|CNT_FAM_MEMBERS|NPL|\n",
      "+---------+-----------+------------+---------------+------------+----------------+--------------------+--------------------+--------------------+-----------------+----------+-------------+----------+---------------+----------+----------+--------------------+---------------+---+\n",
      "|      691|          F|           N|              N|           0|         67500.0|             Working|Secondary / secon...|             Married|House / apartment|    -20075|        -7013|         1|              1|         1|         0|         Sales staff|            2.0|  0|\n",
      "|     3606|          F|           N|              N|           0|        112500.0|             Working|Secondary / secon...|             Married|House / apartment|     -9865|         -196|         1|              1|         0|         0|            Laborers|            2.0|  0|\n",
      "|     4821|          F|           N|              N|           0|        135000.0|       State servant|    Higher education|             Married|House / apartment|    -12490|        -1191|         1|              1|         1|         0|          Core staff|            2.0|  0|\n",
      "|     5925|          F|           N|              N|           0|        157500.0|           Pensioner|Secondary / secon...|             Married|House / apartment|    -22828|       365243|         1|              0|         0|         0|                NULL|            2.0|  0|\n",
      "|     6194|          F|           N|              N|           0|        157500.0|             Working|   Incomplete higher|             Married|House / apartment|    -16888|        -2687|         1|              0|         0|         0|          Core staff|            2.0|  0|\n",
      "|     9583|          F|           N|              N|           0|        364500.0|             Working|Secondary / secon...|      Civil marriage|House / apartment|    -17204|        -1028|         1|              0|         0|         0|         Sales staff|            2.0|  0|\n",
      "|    13442|          F|           N|              Y|           0|         45000.0|           Pensioner|Secondary / secon...|             Married|House / apartment|    -22783|       365243|         1|              0|         1|         0|                NULL|            2.0|  0|\n",
      "|    13772|          F|           N|              Y|           0|         54000.0|             Working|Secondary / secon...|             Married|House / apartment|    -18651|        -7752|         1|              1|         1|         0|                NULL|            2.0|  0|\n",
      "|    15269|          F|           N|              Y|           0|         76500.0|           Pensioner|Secondary / secon...|             Married|House / apartment|    -20931|       365243|         1|              0|         1|         0|                NULL|            2.0|  0|\n",
      "|    15574|          F|           N|              Y|           0|         81000.0|           Pensioner|Secondary / secon...|             Married|House / apartment|    -21383|       365243|         1|              0|         1|         0|                NULL|            2.0|  0|\n",
      "|    16250|          F|           N|              Y|           0|         90000.0|Commercial associate|Secondary / secon...|           Separated|House / apartment|    -19867|         -720|         1|              0|         0|         1|                NULL|            1.0|  0|\n",
      "|    18130|          F|           N|              Y|           0|         99000.0|             Working|Secondary / secon...|             Married|House / apartment|    -19613|        -8152|         1|              1|         0|         0|            Laborers|            2.0|  0|\n",
      "|    26082|          F|           N|              Y|           0|        157500.0|           Pensioner|Secondary / secon...|             Married|House / apartment|    -23758|       365243|         1|              0|         0|         1|                NULL|            2.0|  0|\n",
      "|    27317|          F|           N|              Y|           0|        157500.0|             Working|Secondary / secon...|             Married|House / apartment|    -15035|        -1128|         1|              0|         1|         0|      Cleaning staff|            2.0|  0|\n",
      "|    38271|          F|           N|              Y|           1|        112500.0|             Working|Secondary / secon...|Single / not married|House / apartment|     -9383|         -689|         1|              0|         0|         0|High skill tech s...|            2.0|  0|\n",
      "|    39103|          F|           N|              Y|           1|        135000.0|             Working|Secondary / secon...|             Married|House / apartment|    -10112|        -3170|         1|              1|         1|         0|            Laborers|            3.0|  0|\n",
      "|    39581|          F|           N|              Y|           1|        157500.0|             Working|    Higher education|Single / not married|     With parents|    -10304|         -433|         1|              0|         0|         0|         Secretaries|            2.0|  0|\n",
      "|    50802|          F|           Y|              Y|           0|        144000.0|             Working|    Higher education|             Married|House / apartment|     -8977|         -307|         1|              0|         1|         0|                NULL|            2.0|  0|\n",
      "|    51063|          F|           Y|              Y|           0|        157500.0|           Pensioner|Secondary / secon...|             Married|House / apartment|    -22723|       365243|         1|              0|         0|         0|                NULL|            2.0|  0|\n",
      "|    52991|          F|           Y|              Y|           0|        225000.0|           Pensioner|Secondary / secon...|             Married|House / apartment|    -22920|       365243|         1|              0|         0|         0|                NULL|            2.0|  0|\n",
      "+---------+-----------+------------+---------------+------------+----------------+--------------------+--------------------+--------------------+-----------------+----------+-------------+----------+---------------+----------+----------+--------------------+---------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e465a9e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T10:18:44.512783Z",
     "iopub.status.busy": "2023-12-12T10:18:44.512353Z",
     "iopub.status.idle": "2023-12-12T10:18:44.939337Z",
     "shell.execute_reply": "2023-12-12T10:18:44.937602Z"
    },
    "papermill": {
     "duration": 0.482962,
     "end_time": "2023-12-12T10:18:44.942935",
     "exception": false,
     "start_time": "2023-12-12T10:18:44.459973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---+\n",
      "|OWN_VALUABLE|NPL|\n",
      "+------------+---+\n",
      "|           0|  0|\n",
      "|           0|  0|\n",
      "|           0|  0|\n",
      "|           0|  0|\n",
      "|           0|  0|\n",
      "+------------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Documentar\n",
    "@udf(returnType=StringType())\n",
    "def own_valuable(col_car:str, col_realty:str)->str:\n",
    "    if (col_car=='Y') or (col_realty=='Y'):\n",
    "        return '1'\n",
    "    return '0'\n",
    "\n",
    "df_valuable = train.select(own_valuable('FLAG_OWN_CAR', 'FLAG_OWN_REALTY').alias('OWN_VALUABLE'), 'NPL')\n",
    "df_valuable.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5aaf2f27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T10:18:45.068717Z",
     "iopub.status.busy": "2023-12-12T10:18:45.068163Z",
     "iopub.status.idle": "2023-12-12T10:18:45.077103Z",
     "shell.execute_reply": "2023-12-12T10:18:45.075479Z"
    },
    "papermill": {
     "duration": 0.064382,
     "end_time": "2023-12-12T10:18:45.079744",
     "exception": false,
     "start_time": "2023-12-12T10:18:45.015362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance('oi', str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0faba7bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T10:18:45.181294Z",
     "iopub.status.busy": "2023-12-12T10:18:45.180018Z",
     "iopub.status.idle": "2023-12-12T10:18:45.185394Z",
     "shell.execute_reply": "2023-12-12T10:18:45.184570Z"
    },
    "papermill": {
     "duration": 0.059501,
     "end_time": "2023-12-12T10:18:45.188029",
     "exception": false,
     "start_time": "2023-12-12T10:18:45.128528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from pyspark.sql.functions import un\n",
    "#train.withColumnRenamed('OWN_VALUABLE_ASSET', lambda x: '1' if x['FLAG_OWN_CAR']=='Y' else 'N')\n",
    "#train['NAME_HOUSING_TYPE'].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "71adaa2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T10:18:45.294082Z",
     "iopub.status.busy": "2023-12-12T10:18:45.292945Z",
     "iopub.status.idle": "2023-12-12T10:18:45.480459Z",
     "shell.execute_reply": "2023-12-12T10:18:45.479338Z"
    },
    "papermill": {
     "duration": 0.244264,
     "end_time": "2023-12-12T10:18:45.483167",
     "exception": false,
     "start_time": "2023-12-12T10:18:45.238903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1300"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.where('`DAYS_EMPLOYED`>=0').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3430302c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T10:18:45.584812Z",
     "iopub.status.busy": "2023-12-12T10:18:45.584426Z",
     "iopub.status.idle": "2023-12-12T10:18:45.770550Z",
     "shell.execute_reply": "2023-12-12T10:18:45.769269Z"
    },
    "papermill": {
     "duration": 0.23958,
     "end_time": "2023-12-12T10:18:45.774256",
     "exception": false,
     "start_time": "2023-12-12T10:18:45.534676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1300"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.where('`OCCUPATION_TYPE` IS NULL AND `DAYS_EMPLOYED`>=0').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb71c41f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-12T10:18:45.885264Z",
     "iopub.status.busy": "2023-12-12T10:18:45.884225Z",
     "iopub.status.idle": "2023-12-12T10:18:46.051827Z",
     "shell.execute_reply": "2023-12-12T10:18:46.050829Z"
    },
    "papermill": {
     "duration": 0.22178,
     "end_time": "2023-12-12T10:18:46.054922",
     "exception": false,
     "start_time": "2023-12-12T10:18:45.833142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "978"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.where('`OCCUPATION_TYPE` IS NULL AND `DAYS_EMPLOYED`<0').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53a0a80",
   "metadata": {
    "papermill": {
     "duration": 0.058605,
     "end_time": "2023-12-12T10:18:46.186223",
     "exception": false,
     "start_time": "2023-12-12T10:18:46.127618",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<p style='color:red'> Documentar `own_valuable` Valuable Assets Analysis</p>"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 426827,
     "sourceId": 1031720,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3941029,
     "sourceId": 6856406,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3950750,
     "sourceId": 6875348,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3950752,
     "sourceId": 6875350,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30558,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 414.16855,
   "end_time": "2023-12-12T10:18:48.861468",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-12T10:11:54.692918",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
