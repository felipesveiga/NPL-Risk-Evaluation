{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "348a464f",
   "metadata": {
    "papermill": {
     "duration": 0.00269,
     "end_time": "2023-08-11T16:41:40.606109",
     "exception": false,
     "start_time": "2023-08-11T16:41:40.603419",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 style='font-size:40px'> NPL Risk Evaluation Modeling</h1>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            This project aims the conceiving of a Machine Learning Model focused on assisting a bank on its credit approval strategy.\n",
    "        </li>\n",
    "        <li> \n",
    "            During the planning meetings, the business team has made two major requests concerning the nature of the model.\n",
    "            <ul style='list-style-type:decimal'> \n",
    "                <li> \n",
    "                    It must be focused on predicting potential NPL's based on a set of clients' information.\n",
    "                </li>\n",
    "                <li> \n",
    "                    The output must be some kind of score suggesting the likelihood of the loan to become non-performing. They are not looking for an incisive \"yes or no\" answer.\n",
    "                </li>\n",
    "            </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe12d1e5",
   "metadata": {
    "papermill": {
     "duration": 0.001745,
     "end_time": "2023-08-11T16:41:40.610097",
     "exception": false,
     "start_time": "2023-08-11T16:41:40.608352",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h2 style='font-size:40px'> Data Importing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df14162d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T16:41:40.615837Z",
     "iopub.status.busy": "2023-08-11T16:41:40.615373Z",
     "iopub.status.idle": "2023-08-11T16:42:20.299584Z",
     "shell.execute_reply": "2023-08-11T16:42:20.298529Z"
    },
    "papermill": {
     "duration": 39.689513,
     "end_time": "2023-08-11T16:42:20.301542",
     "exception": false,
     "start_time": "2023-08-11T16:41:40.612029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\r\n",
      "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: py4j==0.10.9.7 in /opt/conda/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\r\n",
      "Building wheels for collected packages: pyspark\r\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285413 sha256=0e43837f012fd495e927d81a97c0417503bf54e7fea56f66c6f01ec60f6c7a3a\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\r\n",
      "Successfully built pyspark\r\n",
      "Installing collected packages: pyspark\r\n",
      "Successfully installed pyspark-3.4.1\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f24166d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T16:42:20.321283Z",
     "iopub.status.busy": "2023-08-11T16:42:20.320863Z",
     "iopub.status.idle": "2023-08-11T16:42:25.355310Z",
     "shell.execute_reply": "2023-08-11T16:42:25.354168Z"
    },
    "papermill": {
     "duration": 5.046909,
     "end_time": "2023-08-11T16:42:25.357728",
     "exception": false,
     "start_time": "2023-08-11T16:42:20.310819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/08/11 16:42:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "# Creating the project's SparkSession.\n",
    "spark = SparkSession.builder.appName('NPL').getOrCreate()\n",
    "\n",
    "# This tiny config enables us to scroll along the DataFrame's columns.\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f84be3a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T16:42:25.376882Z",
     "iopub.status.busy": "2023-08-11T16:42:25.376291Z",
     "iopub.status.idle": "2023-08-11T16:42:30.959337Z",
     "shell.execute_reply": "2023-08-11T16:42:30.958101Z"
    },
    "papermill": {
     "duration": 5.595141,
     "end_time": "2023-08-11T16:42:30.961541",
     "exception": false,
     "start_time": "2023-08-11T16:42:25.366400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+------------+---------------+------------+----------------+--------------------+--------------------+--------------------+-----------------+----------+-------------+----------+---------------+----------+----------+---------------+---------------+\n",
      "|     ID|CODE_GENDER|FLAG_OWN_CAR|FLAG_OWN_REALTY|CNT_CHILDREN|AMT_INCOME_TOTAL|    NAME_INCOME_TYPE| NAME_EDUCATION_TYPE|  NAME_FAMILY_STATUS|NAME_HOUSING_TYPE|DAYS_BIRTH|DAYS_EMPLOYED|FLAG_MOBIL|FLAG_WORK_PHONE|FLAG_PHONE|FLAG_EMAIL|OCCUPATION_TYPE|CNT_FAM_MEMBERS|\n",
      "+-------+-----------+------------+---------------+------------+----------------+--------------------+--------------------+--------------------+-----------------+----------+-------------+----------+---------------+----------+----------+---------------+---------------+\n",
      "|5008804|          M|           Y|              Y|           0|        427500.0|             Working|    Higher education|      Civil marriage| Rented apartment|    -12005|        -4542|         1|              1|         0|         0|           null|            2.0|\n",
      "|5008805|          M|           Y|              Y|           0|        427500.0|             Working|    Higher education|      Civil marriage| Rented apartment|    -12005|        -4542|         1|              1|         0|         0|           null|            2.0|\n",
      "|5008806|          M|           Y|              Y|           0|        112500.0|             Working|Secondary / secon...|             Married|House / apartment|    -21474|        -1134|         1|              0|         0|         0| Security staff|            2.0|\n",
      "|5008808|          F|           N|              Y|           0|        270000.0|Commercial associate|Secondary / secon...|Single / not married|House / apartment|    -19110|        -3051|         1|              0|         1|         1|    Sales staff|            1.0|\n",
      "|5008809|          F|           N|              Y|           0|        270000.0|Commercial associate|Secondary / secon...|Single / not married|House / apartment|    -19110|        -3051|         1|              0|         1|         1|    Sales staff|            1.0|\n",
      "|5008810|          F|           N|              Y|           0|        270000.0|Commercial associate|Secondary / secon...|Single / not married|House / apartment|    -19110|        -3051|         1|              0|         1|         1|    Sales staff|            1.0|\n",
      "|5008811|          F|           N|              Y|           0|        270000.0|Commercial associate|Secondary / secon...|Single / not married|House / apartment|    -19110|        -3051|         1|              0|         1|         1|    Sales staff|            1.0|\n",
      "|5008812|          F|           N|              Y|           0|        283500.0|           Pensioner|    Higher education|           Separated|House / apartment|    -22464|       365243|         1|              0|         0|         0|           null|            1.0|\n",
      "|5008813|          F|           N|              Y|           0|        283500.0|           Pensioner|    Higher education|           Separated|House / apartment|    -22464|       365243|         1|              0|         0|         0|           null|            1.0|\n",
      "|5008814|          F|           N|              Y|           0|        283500.0|           Pensioner|    Higher education|           Separated|House / apartment|    -22464|       365243|         1|              0|         0|         0|           null|            1.0|\n",
      "+-------+-----------+------------+---------------+------------+----------------+--------------------+--------------------+--------------------+-----------------+----------+-------------+----------+---------------+----------+----------+---------------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "path_clients = '/kaggle/input/credit-card-approval-prediction/application_record.csv'\n",
    "\n",
    "# Defining the data types from the clients dataset.\n",
    "schema_clients = '''\n",
    "`ID` STRING, `CODE_GENDER` STRING, `FLAG_OWN_CAR` STRING, `FLAG_OWN_REALTY` STRING, `CNT_CHILDREN` INT,\n",
    "`AMT_INCOME_TOTAL` FLOAT, `NAME_INCOME_TYPE` STRING, `NAME_EDUCATION_TYPE` STRING, `NAME_FAMILY_STATUS` STRING, `NAME_HOUSING_TYPE` STRING,\n",
    "`DAYS_BIRTH` INT, `DAYS_EMPLOYED` INT, `FLAG_MOBIL` STRING, `FLAG_WORK_PHONE` STRING, `FLAG_PHONE` STRING, `FLAG_EMAIL` STRING, \n",
    "`OCCUPATION_TYPE` STRING, `CNT_FAM_MEMBERS` DOUBLE\n",
    "'''\n",
    "df_clients = spark.read.csv(path_clients, header=True, schema=schema_clients)\n",
    "df_clients.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8654888",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-11T16:42:30.990329Z",
     "iopub.status.busy": "2023-08-11T16:42:30.989884Z",
     "iopub.status.idle": "2023-08-11T16:42:31.251345Z",
     "shell.execute_reply": "2023-08-11T16:42:31.250090Z"
    },
    "papermill": {
     "duration": 0.280114,
     "end_time": "2023-08-11T16:42:31.254430",
     "exception": false,
     "start_time": "2023-08-11T16:42:30.974316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+------+\n",
      "|     ID|MONTHS_BALANCE|STATUS|\n",
      "+-------+--------------+------+\n",
      "|5001711|             0|     X|\n",
      "|5001711|            -1|     0|\n",
      "|5001711|            -2|     0|\n",
      "|5001711|            -3|     0|\n",
      "|5001712|             0|     C|\n",
      "+-------+--------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_loans = '/kaggle/input/credit-card-approval-prediction/credit_record.csv'\n",
    "schema_loans = '`ID` STRING, `MONTHS_BALANCE` INT, `STATUS` STRING'\n",
    "df_loans = spark.read.csv(path_loans, header=True, schema=schema_loans)\n",
    "df_loans.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0e610f",
   "metadata": {
    "papermill": {
     "duration": 0.011854,
     "end_time": "2023-08-11T16:42:31.278255",
     "exception": false,
     "start_time": "2023-08-11T16:42:31.266401",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<p style='color:red'> Documentar data importing; Esclarecimento sobre colunas de tempo;</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 63.75894,
   "end_time": "2023-08-11T16:42:33.911212",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-08-11T16:41:30.152272",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
