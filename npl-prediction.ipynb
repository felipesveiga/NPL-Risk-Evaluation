{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "944a192b",
   "metadata": {
    "papermill": {
     "duration": 0.005175,
     "end_time": "2023-09-06T16:09:12.170296",
     "exception": false,
     "start_time": "2023-09-06T16:09:12.165121",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h1 style='font-size:40px'> NPL Risk Evaluation Modeling</h1>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            This project aims the conceiving of a Machine Learning Model focused on assisting a bank on its credit approval strategy.\n",
    "        </li>\n",
    "        <li> \n",
    "            During the planning meetings, the business team has made two major requests concerning the nature of the model.\n",
    "            <ul style='list-style-type:decimal'> \n",
    "                <li> \n",
    "                    It must be focused on predicting whether a given client might produce an NPL in the future.\n",
    "                </li>\n",
    "                <li> \n",
    "                    The output must be some kind of score suggesting the likelihood of thi event to happen. They are not looking for \n",
    "                    an incisive \"yes or no\" answer.\n",
    "                </li>\n",
    "            </ul>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab7f958",
   "metadata": {
    "papermill": {
     "duration": 0.004129,
     "end_time": "2023-09-06T16:09:12.179072",
     "exception": false,
     "start_time": "2023-09-06T16:09:12.174943",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h2 style='font-size:30px'> Data Importing</h2>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            The Data Engineers were able to provide two .csv views from the bank's database. The first one contains general information over the clients \n",
    "            and the second lists the loans they've contracted over some period of time.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9ac9c1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-06T16:09:12.189391Z",
     "iopub.status.busy": "2023-09-06T16:09:12.189004Z",
     "iopub.status.idle": "2023-09-06T16:10:00.935240Z",
     "shell.execute_reply": "2023-09-06T16:10:00.933530Z"
    },
    "papermill": {
     "duration": 48.754399,
     "end_time": "2023-09-06T16:10:00.937865",
     "exception": false,
     "start_time": "2023-09-06T16:09:12.183466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\r\n",
      "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: py4j==0.10.9.7 in /opt/conda/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\r\n",
      "Building wheels for collected packages: pyspark\r\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285413 sha256=b22c800d45f8f1b2417a6b08883a6406cea4e27b1e1a0d32859b5700fbc22b2c\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\r\n",
      "Successfully built pyspark\r\n",
      "Installing collected packages: pyspark\r\n",
      "Successfully installed pyspark-3.4.1\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "497d7509",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-06T16:10:00.966878Z",
     "iopub.status.busy": "2023-09-06T16:10:00.966425Z",
     "iopub.status.idle": "2023-09-06T16:10:06.715425Z",
     "shell.execute_reply": "2023-09-06T16:10:06.714508Z"
    },
    "papermill": {
     "duration": 5.767077,
     "end_time": "2023-09-06T16:10:06.717929",
     "exception": false,
     "start_time": "2023-09-06T16:10:00.950852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/09/06 16:10:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "# Creating the project's SparkSession.\n",
    "spark = SparkSession.builder.appName('NPL').getOrCreate()\n",
    "\n",
    "# Also, modifying the session's log level.\n",
    "log_level = spark.sparkContext.setLogLevel('ERROR')\n",
    "\n",
    "# This tiny config enables us to scroll along the DataFrame's columns.\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b024d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-15T16:05:33.192895Z",
     "iopub.status.busy": "2023-08-15T16:05:33.192467Z",
     "iopub.status.idle": "2023-08-15T16:05:34.343874Z",
     "shell.execute_reply": "2023-08-15T16:05:34.342739Z",
     "shell.execute_reply.started": "2023-08-15T16:05:33.192858Z"
    },
    "papermill": {
     "duration": 0.013047,
     "end_time": "2023-09-06T16:10:06.744217",
     "exception": false,
     "start_time": "2023-09-06T16:10:06.731170",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Clients Database</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            This dataset is comprised of general personal and professional information about the loans' clients.\n",
    "        </li>    \n",
    "        <li> \n",
    "            A particularity worth noting is that date columns show the negative amount of days since the given event took place. Positive numbers \n",
    "            indicate the number of days since the occurence ceased to exist - as it might happen with unemployed borrowers in the DAYS_EMPLOYED feature.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e3669f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-06T16:10:06.772690Z",
     "iopub.status.busy": "2023-09-06T16:10:06.771774Z",
     "iopub.status.idle": "2023-09-06T16:10:13.611751Z",
     "shell.execute_reply": "2023-09-06T16:10:13.610420Z"
    },
    "papermill": {
     "duration": 6.85827,
     "end_time": "2023-09-06T16:10:13.615135",
     "exception": false,
     "start_time": "2023-09-06T16:10:06.756865",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+------------+---------------+------------+----------------+--------------------+--------------------+--------------------+-----------------+----------+-------------+----------+---------------+----------+----------+---------------+---------------+\n",
      "|     ID|CODE_GENDER|FLAG_OWN_CAR|FLAG_OWN_REALTY|CNT_CHILDREN|AMT_INCOME_TOTAL|    NAME_INCOME_TYPE| NAME_EDUCATION_TYPE|  NAME_FAMILY_STATUS|NAME_HOUSING_TYPE|DAYS_BIRTH|DAYS_EMPLOYED|FLAG_MOBIL|FLAG_WORK_PHONE|FLAG_PHONE|FLAG_EMAIL|OCCUPATION_TYPE|CNT_FAM_MEMBERS|\n",
      "+-------+-----------+------------+---------------+------------+----------------+--------------------+--------------------+--------------------+-----------------+----------+-------------+----------+---------------+----------+----------+---------------+---------------+\n",
      "|5008804|          M|           Y|              Y|           0|        427500.0|             Working|    Higher education|      Civil marriage| Rented apartment|    -12005|        -4542|         1|              1|         0|         0|           null|            2.0|\n",
      "|5008805|          M|           Y|              Y|           0|        427500.0|             Working|    Higher education|      Civil marriage| Rented apartment|    -12005|        -4542|         1|              1|         0|         0|           null|            2.0|\n",
      "|5008806|          M|           Y|              Y|           0|        112500.0|             Working|Secondary / secon...|             Married|House / apartment|    -21474|        -1134|         1|              0|         0|         0| Security staff|            2.0|\n",
      "|5008808|          F|           N|              Y|           0|        270000.0|Commercial associate|Secondary / secon...|Single / not married|House / apartment|    -19110|        -3051|         1|              0|         1|         1|    Sales staff|            1.0|\n",
      "|5008809|          F|           N|              Y|           0|        270000.0|Commercial associate|Secondary / secon...|Single / not married|House / apartment|    -19110|        -3051|         1|              0|         1|         1|    Sales staff|            1.0|\n",
      "+-------+-----------+------------+---------------+------------+----------------+--------------------+--------------------+--------------------+-----------------+----------+-------------+----------+---------------+----------+----------+---------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "path_clients = '/kaggle/input/credit-card-approval-prediction/application_record.csv'\n",
    "\n",
    "# Defining the data types from the clients dataset.\n",
    "schema_clients = '''\n",
    "`ID` STRING, `CODE_GENDER` STRING, `FLAG_OWN_CAR` STRING, `FLAG_OWN_REALTY` STRING, `CNT_CHILDREN` INT,\n",
    "`AMT_INCOME_TOTAL` FLOAT, `NAME_INCOME_TYPE` STRING, `NAME_EDUCATION_TYPE` STRING, `NAME_FAMILY_STATUS` STRING, `NAME_HOUSING_TYPE` STRING,\n",
    "`DAYS_BIRTH` INT, `DAYS_EMPLOYED` INT, `FLAG_MOBIL` STRING, `FLAG_WORK_PHONE` STRING, `FLAG_PHONE` STRING, `FLAG_EMAIL` STRING, \n",
    "`OCCUPATION_TYPE` STRING, `CNT_FAM_MEMBERS` DOUBLE\n",
    "'''\n",
    "\n",
    "# Reading the database with the created schema.\n",
    "df_clients = spark.read.csv(path_clients, header=True, schema=schema_clients)\n",
    "df_clients.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8111fc",
   "metadata": {
    "papermill": {
     "duration": 0.020622,
     "end_time": "2023-09-06T16:10:13.656462",
     "exception": false,
     "start_time": "2023-09-06T16:10:13.635840",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> Duplicates Disclaimer</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "             Clients may not have unique rows in the dataset because the ID column identifies a loan contracted instead of a person.\n",
    "        </li>\n",
    "        <li> \n",
    "            Thus, I've found convenient for the project to create an ID column that assigns a code for the clients\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6699f22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-06T16:10:13.701886Z",
     "iopub.status.busy": "2023-09-06T16:10:13.700920Z",
     "iopub.status.idle": "2023-09-06T16:10:13.736677Z",
     "shell.execute_reply": "2023-09-06T16:10:13.735636Z"
    },
    "papermill": {
     "duration": 0.061861,
     "end_time": "2023-09-06T16:10:13.739325",
     "exception": false,
     "start_time": "2023-09-06T16:10:13.677464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CODE_GENDER',\n",
       " 'FLAG_OWN_CAR',\n",
       " 'FLAG_OWN_REALTY',\n",
       " 'CNT_CHILDREN',\n",
       " 'AMT_INCOME_TOTAL',\n",
       " 'NAME_INCOME_TYPE',\n",
       " 'NAME_EDUCATION_TYPE',\n",
       " 'NAME_FAMILY_STATUS',\n",
       " 'NAME_HOUSING_TYPE',\n",
       " 'DAYS_BIRTH',\n",
       " 'DAYS_EMPLOYED',\n",
       " 'FLAG_MOBIL',\n",
       " 'FLAG_WORK_PHONE',\n",
       " 'FLAG_PHONE',\n",
       " 'FLAG_EMAIL',\n",
       " 'OCCUPATION_TYPE',\n",
       " 'CNT_FAM_MEMBERS']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Listing the `df_clients` features with the exception of ID.\n",
    "features_clients = df_clients.columns\n",
    "features_clients.remove('ID')\n",
    "features_clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9434413d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-06T16:10:13.771243Z",
     "iopub.status.busy": "2023-09-06T16:10:13.770303Z",
     "iopub.status.idle": "2023-09-06T16:10:18.745500Z",
     "shell.execute_reply": "2023-09-06T16:10:18.744427Z"
    },
    "papermill": {
     "duration": 4.993557,
     "end_time": "2023-09-06T16:10:18.749221",
     "exception": false,
     "start_time": "2023-09-06T16:10:13.755664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`df_clients` length: 438557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:==============>                                            (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clients: 90085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Note that the database's actual amount of clients is lower than its number of rows. \n",
    "data_clients = df_clients.dropDuplicates(features_clients)\n",
    "print(f'`df_clients` length: {df_clients.count()}')\n",
    "print(f'Number of clients: {data_clients.count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8101a4d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-06T16:10:18.793878Z",
     "iopub.status.busy": "2023-09-06T16:10:18.793383Z",
     "iopub.status.idle": "2023-09-06T16:10:19.004987Z",
     "shell.execute_reply": "2023-09-06T16:10:19.003709Z"
    },
    "papermill": {
     "duration": 0.237042,
     "end_time": "2023-09-06T16:10:19.007778",
     "exception": false,
     "start_time": "2023-09-06T16:10:18.770736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We'll assign a Client ID for every Loan ID present in `df_clients`. \n",
    "from pyspark.sql.functions import cast, row_number\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "window = Window.orderBy(features_clients)\n",
    "row_window = row_number().over(window)\n",
    "id_clients = data_clients.withColumn('ID_CLIENT', row_window.cast(StringType())).drop('ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3db0f5be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-06T16:10:19.040163Z",
     "iopub.status.busy": "2023-09-06T16:10:19.039153Z",
     "iopub.status.idle": "2023-09-06T16:10:27.913091Z",
     "shell.execute_reply": "2023-09-06T16:10:27.911973Z"
    },
    "papermill": {
     "duration": 8.892577,
     "end_time": "2023-09-06T16:10:27.916739",
     "exception": false,
     "start_time": "2023-09-06T16:10:19.024162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+---------------+------------+----------------+----------------+--------------------+------------------+-----------------+----------+-------------+----------+---------------+----------+----------+---------------+---------------+-------+---------+\n",
      "|CODE_GENDER|FLAG_OWN_CAR|FLAG_OWN_REALTY|CNT_CHILDREN|AMT_INCOME_TOTAL|NAME_INCOME_TYPE| NAME_EDUCATION_TYPE|NAME_FAMILY_STATUS|NAME_HOUSING_TYPE|DAYS_BIRTH|DAYS_EMPLOYED|FLAG_MOBIL|FLAG_WORK_PHONE|FLAG_PHONE|FLAG_EMAIL|OCCUPATION_TYPE|CNT_FAM_MEMBERS|     ID|ID_CLIENT|\n",
      "+-----------+------------+---------------+------------+----------------+----------------+--------------------+------------------+-----------------+----------+-------------+----------+---------------+----------+----------+---------------+---------------+-------+---------+\n",
      "|          F|           N|              N|           0|         36000.0|         Working|Secondary / secon...|           Married|House / apartment|    -13673|        -3687|         1|              0|         0|         0|     Core staff|            2.0|5609571|       42|\n",
      "|          F|           N|              N|           0|         36000.0|         Working|Secondary / secon...|           Married|House / apartment|    -13673|        -3687|         1|              0|         0|         0|     Core staff|            2.0|5609572|       42|\n",
      "|          F|           N|              N|           0|         36000.0|         Working|Secondary / secon...|           Married|House / apartment|    -13673|        -3687|         1|              0|         0|         0|     Core staff|            2.0|5609573|       42|\n",
      "|          F|           N|              N|           0|         36000.0|         Working|Secondary / secon...|           Married|     With parents|    -14500|         -459|         1|              1|         0|         0|     Core staff|            2.0|5090400|       45|\n",
      "|          F|           N|              N|           0|         36000.0|         Working|Secondary / secon...|           Married|     With parents|    -14500|         -459|         1|              1|         0|         0|     Core staff|            2.0|5787892|       45|\n",
      "+-----------+------------+---------------+------------+----------------+----------------+--------------------+------------------+-----------------+----------+-------------+----------+---------------+----------+----------+---------------+---------------+-------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now, we only need to enrich `df_clients` with the clients' actual identification.\n",
    "\n",
    "# Performing an INNER JOIN between `df_clients` and `id_clients` using all non-ID columns as keys.\n",
    "df_clients = df_clients.join(id_clients, on=features_clients)\n",
    "df_clients.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb160e18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-15T16:05:33.192895Z",
     "iopub.status.busy": "2023-08-15T16:05:33.192467Z",
     "iopub.status.idle": "2023-08-15T16:05:34.343874Z",
     "shell.execute_reply": "2023-08-15T16:05:34.342739Z",
     "shell.execute_reply.started": "2023-08-15T16:05:33.192858Z"
    },
    "papermill": {
     "duration": 0.021727,
     "end_time": "2023-09-06T16:10:27.960879",
     "exception": false,
     "start_time": "2023-09-06T16:10:27.939152",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h3 style='font-size:30px;font-style:italic'> Loans Database</h3>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            This table contains the payments records for every loan since its contraction. \n",
    "        </li>\n",
    "        <li> \n",
    "            But in order to the dataset be adequate to our project's intent, two transformations are necessary: first, we need to bring the `ID_CLIENT`\n",
    "            column to it and after that, group the database so that it denounces individuals who've produced an NPL at least once.            \n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c8d278f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-06T16:10:28.008354Z",
     "iopub.status.busy": "2023-09-06T16:10:28.007820Z",
     "iopub.status.idle": "2023-09-06T16:10:28.224830Z",
     "shell.execute_reply": "2023-09-06T16:10:28.223635Z"
    },
    "papermill": {
     "duration": 0.244972,
     "end_time": "2023-09-06T16:10:28.228579",
     "exception": false,
     "start_time": "2023-09-06T16:10:27.983607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+------+\n",
      "|     ID|MONTHS_BALANCE|STATUS|\n",
      "+-------+--------------+------+\n",
      "|5001711|             0|     X|\n",
      "|5001711|            -1|     0|\n",
      "|5001711|            -2|     0|\n",
      "|5001711|            -3|     0|\n",
      "|5001712|             0|     C|\n",
      "+-------+--------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Bringing the dataset into our notebook.\n",
    "path_loans = '/kaggle/input/credit-card-approval-prediction/credit_record.csv'\n",
    "schema_loans = '`ID` STRING, `MONTHS_BALANCE` INT, `STATUS` STRING'\n",
    "df_loans = spark.read.csv(path_loans, header=True, schema=schema_loans)\n",
    "df_loans.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c51be7f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-06T16:10:28.277223Z",
     "iopub.status.busy": "2023-09-06T16:10:28.276704Z",
     "iopub.status.idle": "2023-09-06T16:10:39.149574Z",
     "shell.execute_reply": "2023-09-06T16:10:39.148389Z"
    },
    "papermill": {
     "duration": 10.9022,
     "end_time": "2023-09-06T16:10:39.153602",
     "exception": false,
     "start_time": "2023-09-06T16:10:28.251402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 35:=============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+--------------+------+\n",
      "|ID_CLIENT|     ID|MONTHS_BALANCE|STATUS|\n",
      "+---------+-------+--------------+------+\n",
      "|    34270|5008810|             0|     C|\n",
      "|    34270|5008810|            -1|     C|\n",
      "|    34270|5008810|            -2|     C|\n",
      "|    34270|5008810|            -3|     C|\n",
      "|    34270|5008810|            -4|     C|\n",
      "+---------+-------+--------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Now, providing the loans' client ID.\n",
    "df_loans = df_loans.join(df_clients, ['ID']).select(['ID_CLIENT', 'ID', 'MONTHS_BALANCE', 'STATUS'])\n",
    "df_loans.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d86666",
   "metadata": {
    "papermill": {
     "duration": 0.022584,
     "end_time": "2023-09-06T16:10:39.216965",
     "exception": false,
     "start_time": "2023-09-06T16:10:39.194381",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<h4 style='font-size:30px;font-style:italic;text-decoration:underline'> Conceiving the Target Variable</h4>\n",
    "<div> \n",
    "    <ul style='font-size:20px'> \n",
    "        <li> \n",
    "            The `STATUS` column presents a handful of codes that represent distinct status for a loan's payment.\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6265f813",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-06T16:10:39.248589Z",
     "iopub.status.busy": "2023-09-06T16:10:39.248103Z",
     "iopub.status.idle": "2023-09-06T16:10:43.999710Z",
     "shell.execute_reply": "2023-09-06T16:10:43.998483Z"
    },
    "papermill": {
     "duration": 4.770829,
     "end_time": "2023-09-06T16:10:44.002836",
     "exception": false,
     "start_time": "2023-09-06T16:10:39.232007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 50:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+--------------+------+\n",
      "|ID_CLIENT|     ID|MONTHS_BALANCE|STATUS|\n",
      "+---------+-------+--------------+------+\n",
      "|    27939|5021831|             0|     C|\n",
      "|    27939|5021831|            -1|     C|\n",
      "|    27939|5021831|            -2|     C|\n",
      "|    27939|5021831|            -3|     C|\n",
      "|    27939|5021831|            -4|     C|\n",
      "|    27939|5021831|            -5|     C|\n",
      "|    27939|5021831|            -6|     C|\n",
      "|    27939|5021831|            -7|     C|\n",
      "|    27939|5021831|            -8|     C|\n",
      "|    27939|5021831|            -9|     C|\n",
      "|    27939|5021831|           -10|     C|\n",
      "|    27939|5021831|           -11|     C|\n",
      "|    27939|5021831|           -12|     C|\n",
      "|    27939|5021831|           -13|     C|\n",
      "|    27939|5021831|           -14|     0|\n",
      "|    27939|5021831|           -15|     0|\n",
      "|    27939|5021831|           -16|     0|\n",
      "|    27939|5021831|           -17|     X|\n",
      "+---------+-------+--------------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_loans.where(df_loans.ID=='5021831').show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41796daa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-06T16:10:44.066129Z",
     "iopub.status.busy": "2023-09-06T16:10:44.065653Z",
     "iopub.status.idle": "2023-09-06T16:10:50.904058Z",
     "shell.execute_reply": "2023-09-06T16:10:50.902703Z"
    },
    "papermill": {
     "duration": 6.868748,
     "end_time": "2023-09-06T16:10:50.908472",
     "exception": false,
     "start_time": "2023-09-06T16:10:44.039724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 71:>                                                         (0 + 4) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|     ID|\n",
      "+-------+\n",
      "|5078867|\n",
      "|5148962|\n",
      "|5112594|\n",
      "|5021831|\n",
      "|5118476|\n",
      "|5105322|\n",
      "|5024053|\n",
      "|5116149|\n",
      "|5113295|\n",
      "|5056011|\n",
      "|5113366|\n",
      "|5100417|\n",
      "|5045994|\n",
      "|5116353|\n",
      "|5023549|\n",
      "|5008944|\n",
      "|5025203|\n",
      "|5028932|\n",
      "|5028940|\n",
      "|5116431|\n",
      "+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_loans.select('ID').where(df_loans.STATUS=='X').distinct().show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5407b86",
   "metadata": {
    "papermill": {
     "duration": 0.026035,
     "end_time": "2023-09-06T16:10:50.968093",
     "exception": false,
     "start_time": "2023-09-06T16:10:50.942058",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "0: 1-29 days past due 1: 30-59 days past due 2: 60-89 days overdue 3: 90-119 days overdue 4: 120-149 days overdue 5: Overdue or bad debts, write-offs for more than 150 days C: paid off that month X: No loan for the month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c985ae",
   "metadata": {
    "papermill": {
     "duration": 0.025255,
     "end_time": "2023-09-06T16:10:51.019349",
     "exception": false,
     "start_time": "2023-09-06T16:10:50.994094",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<table> \n",
    "    <tr>\n",
    "        <th> a</th>\n",
    "        <th> a</th>\n",
    "    </tr>\n",
    "    <tr> \n",
    "        <td> S</td>\n",
    "        <td> S</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec711fe",
   "metadata": {
    "papermill": {
     "duration": 0.015609,
     "end_time": "2023-09-06T16:10:51.056004",
     "exception": false,
     "start_time": "2023-09-06T16:10:51.040395",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<p style='color:red'> Terminar documentação Loans Database; explicar os códigos de STATUS. O que fazer com linhas com STATUS='X' (acho que elas sempre são \n",
    "    o registro mais antigo de um empréstimo)?</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 111.179554,
   "end_time": "2023-09-06T16:10:53.695899",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-09-06T16:09:02.516345",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
